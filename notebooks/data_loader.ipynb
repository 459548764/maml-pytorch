{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- すべての言語の文字を混ぜて問題を作っている。\n",
    "- すべての文字を均等に学習に使いたい的な？\n",
    "\n",
    "\n",
    "- サブ問題だけで学習させた時、すべての文字を一色単に混ぜて学習させた時と比較する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "\n",
    "\n",
    "# 何を返せばいいの？\n",
    "class Omniglot(data.Dataset):\n",
    "    def __init__(self, num_classes, num_instances, mode='train'):\n",
    "        \n",
    "        self.root = '../omniglot/images_background' if mode == 'train' else 'omniglot/images_evaluation'\n",
    "        \n",
    "        languages = os.listdir(self.root) # すべての言語\n",
    "        \n",
    "        chars = [] # すべての文字の一覧。言語の区別はしない。一次元のリスト。\n",
    "        for l in languages:\n",
    "            chars += [os.path.join(l, x) for x in os.listdir(os.path.join(self.root, l))]            \n",
    "        print(\"chars[:10]\\n\", chars[:10], \"\\n\")\n",
    "        \n",
    "        classes = random.sample(chars, num_classes)\n",
    "        print(\"classes\\n\", classes, \"\\n\")\n",
    "        \n",
    "        labels = np.array(range(len(classes)))\n",
    "        labels = dict(zip(classes, labels)) \n",
    "        print(\"labels\\n\", labels, \"\\n\")\n",
    "        \n",
    "        instances = dict()\n",
    "        \n",
    "        self.train_ids = []\n",
    "        self.val_ids = []\n",
    "\n",
    "        # 各クラスから同数ずつtrainとvalをサンプリングする\n",
    "        for c in classes:\n",
    "            temp = [os.path.join(c, x) for x in os.listdir(os.path.join(self.root, c))]\n",
    "            instances[c] = random.sample(temp, len(temp)) # random.shuffleだと代入できない。\n",
    "            self.train_ids += instances[c][:num_instances]\n",
    "            self.val_ids += instances[c][num_instances:num_instances*2]\n",
    "        \n",
    "        print(\"self.train_ids\\n\", self.train_ids, \"\\n\")\n",
    "        print(\"self.val_ids\\n\", self.val_ids, \"\\n\")\n",
    "        self.train_labels = [labels[self.get_class(x)] for x in self.train_ids]\n",
    "        self.val_labels = [labels[self.get_class(x)] for x in self.val_ids]\n",
    "        \n",
    "        # 各クラスから順に1枚ずつとるので、np.arange(20)みたいな結果になる\n",
    "        print(\"self.train_labels\\n\", self.train_labels, \"\\n\")\n",
    "        print(\"self.val_labels\\n\", self.val_labels, \"\\n\")\n",
    "        \n",
    "    def get_class(self, instance):\n",
    "        return os.path.join(*instance.split('/')[:-1])\n",
    "        \n",
    "\n",
    "    \n",
    "    def load_image(self, idx):\n",
    "        im = Image.open('{}/{}'.format(self.root, idx)).convert('RGB')\n",
    "        im = im.resize((28,28), resample=Image.LANCZOS) # per Chelsea's implementation\n",
    "        im = np.array(im, dtype=np.float32)\n",
    "        return im\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_ids[idx]\n",
    "        im = self.load_image(img_id)\n",
    "        if self.transform is not None:\n",
    "            im = self.transform(im)\n",
    "        label = self.labels[idx]\n",
    "        if self.target_transform is not None:\n",
    "            label = self.target_transform(label)\n",
    "        return im, label\n",
    "    \n",
    "    def __iter__(self):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chars[:10]\n",
      " ['Hebrew/character12', 'Hebrew/character02', 'Hebrew/character09', 'Hebrew/character07', 'Hebrew/character19', 'Hebrew/character21', 'Hebrew/character11', 'Hebrew/character18', 'Hebrew/character15', 'Hebrew/character14'] \n",
      "\n",
      "classes\n",
      " ['Alphabet_of_the_Magi/character20', 'Arcadian/character01', 'Tifinagh/character26', 'Grantha/character16', 'Braille/character10', 'Japanese_(hiragana)/character19', 'Balinese/character02', 'Armenian/character04', 'N_Ko/character03', 'Inuktitut_(Canadian_Aboriginal_Syllabics)/character11', 'Tifinagh/character29', 'Syriac_(Estrangelo)/character01', 'Futurama/character12', 'Gujarati/character04', 'Tifinagh/character30', 'Japanese_(katakana)/character06', 'Grantha/character41', 'Gujarati/character02', 'Tifinagh/character33', 'Asomtavruli_(Georgian)/character39'] \n",
      "\n",
      "labels\n",
      " {'Alphabet_of_the_Magi/character20': 0, 'Arcadian/character01': 1, 'Tifinagh/character26': 2, 'Grantha/character16': 3, 'Braille/character10': 4, 'Japanese_(hiragana)/character19': 5, 'Balinese/character02': 6, 'Armenian/character04': 7, 'N_Ko/character03': 8, 'Inuktitut_(Canadian_Aboriginal_Syllabics)/character11': 9, 'Tifinagh/character29': 10, 'Syriac_(Estrangelo)/character01': 11, 'Futurama/character12': 12, 'Gujarati/character04': 13, 'Tifinagh/character30': 14, 'Japanese_(katakana)/character06': 15, 'Grantha/character41': 16, 'Gujarati/character02': 17, 'Tifinagh/character33': 18, 'Asomtavruli_(Georgian)/character39': 19} \n",
      "\n",
      "self.train_ids\n",
      " ['Alphabet_of_the_Magi/character20/0728_08.png', 'Arcadian/character01/0001_10.png', 'Tifinagh/character26/0935_13.png', 'Grantha/character16/0366_12.png', 'Braille/character10/0201_13.png', 'Japanese_(hiragana)/character19/0506_19.png', 'Balinese/character02/0109_20.png', 'Armenian/character04/0030_14.png', 'N_Ko/character03/0806_16.png', 'Inuktitut_(Canadian_Aboriginal_Syllabics)/character11/0550_18.png', 'Tifinagh/character29/0938_20.png', 'Syriac_(Estrangelo)/character01/0273_03.png', 'Futurama/character12/0336_03.png', 'Gujarati/character04/0421_16.png', 'Tifinagh/character30/0939_05.png', 'Japanese_(katakana)/character06/0601_13.png', 'Grantha/character41/0391_05.png', 'Gujarati/character02/0419_20.png', 'Tifinagh/character33/0942_06.png', 'Asomtavruli_(Georgian)/character39/0106_12.png'] \n",
      "\n",
      "self.val_ids\n",
      " ['Alphabet_of_the_Magi/character20/0728_04.png', 'Arcadian/character01/0001_15.png', 'Tifinagh/character26/0935_07.png', 'Grantha/character16/0366_06.png', 'Braille/character10/0201_11.png', 'Japanese_(hiragana)/character19/0506_01.png', 'Balinese/character02/0109_01.png', 'Armenian/character04/0030_16.png', 'N_Ko/character03/0806_12.png', 'Inuktitut_(Canadian_Aboriginal_Syllabics)/character11/0550_09.png', 'Tifinagh/character29/0938_10.png', 'Syriac_(Estrangelo)/character01/0273_15.png', 'Futurama/character12/0336_06.png', 'Gujarati/character04/0421_05.png', 'Tifinagh/character30/0939_13.png', 'Japanese_(katakana)/character06/0601_12.png', 'Grantha/character41/0391_04.png', 'Gujarati/character02/0419_01.png', 'Tifinagh/character33/0942_03.png', 'Asomtavruli_(Georgian)/character39/0106_17.png'] \n",
      "\n",
      "self.train_labels\n",
      " [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19] \n",
      "\n",
      "self.val_labels\n",
      " [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "omniglot = Omniglot(20, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
