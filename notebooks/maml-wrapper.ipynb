{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from skimage import io\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "from collections import OrderedDict\n",
    "from more_itertools import chunked\n",
    "\n",
    "n_shot = 1\n",
    "n_class = 10\n",
    "n_local_update = 5\n",
    "batch_size = n_class\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "class OmniglotNet(nn.Module):\n",
    "    def __init__(self, n_class):\n",
    "        super(OmniglotNet, self).__init__()\n",
    "        \n",
    "        self.h=64\n",
    "        self.conv1 = nn.Conv2d(1, self.h, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(self.h, self.h, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(self.h, self.h, kernel_size=3)\n",
    "        self.bn1 = nn.BatchNorm2d(self.h, momentum=1, affine=True)\n",
    "        self.bn2 = nn.BatchNorm2d(self.h, momentum=1, affine=True)\n",
    "        self.bn3 = nn.BatchNorm2d(self.h, momentum=1, affine=True)\n",
    "        self.fc = nn.Linear(self.h, n_class)\n",
    "        \n",
    "        # init is very very important!!!\n",
    "        # no init version -> HASH:ef56239\n",
    "        init.xavier_normal_(self.conv1.weight)\n",
    "        init.constant_(self.conv1.bias, 0)\n",
    "        init.xavier_normal_(self.conv2.weight)\n",
    "        init.constant_(self.conv2.bias, 0)\n",
    "        init.xavier_normal_(self.conv3.weight)\n",
    "        init.constant_(self.conv3.bias, 0)\n",
    "        \n",
    "        init.constant_(self.bn1.weight, 1)\n",
    "        init.constant_(self.bn1.bias, 0)\n",
    "        init.constant_(self.bn2.weight, 1)\n",
    "        init.constant_(self.bn2.bias, 0)\n",
    "        init.constant_(self.bn3.weight, 1)\n",
    "        init.constant_(self.bn3.bias, 0)\n",
    "        \n",
    "        init.normal_(self.fc.weight, 0, 0.01)\n",
    "        init.constant_(self.fc.bias, 1) # not 0 but 1.\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.max_pool2d(F.relu(self.bn1(self.conv1(x))), 2)\n",
    "        x = F.max_pool2d(F.relu(self.bn2(self.conv2(x))), 2)\n",
    "        x = F.max_pool2d(F.relu(self.bn3(self.conv3(x))), 2)\n",
    "        x = x.view(x.size(0), self.h)\n",
    "        x = self.fc(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    # for MAML local optimization\n",
    "    def manual_forward(self, x, params):\n",
    "        \n",
    "        x = F.conv2d(x, params['conv1.weight'].to(device), params['conv1.bias'].to(device))\n",
    "        dumy = torch.ones(np.prod(np.array(x.data.size()[1]))).cuda()*999999999999999999 # momentnum=1\n",
    "        x = F.batch_norm(x, dumy, dumy, params['bn1.weight'], params['bn1.bias'], True, momentum=1)\n",
    "        x = F.max_pool2d(F.relu(x), 2)\n",
    "        \n",
    "        x = F.conv2d(x, params['conv2.weight'].to(device), params['conv2.bias'].to(device))\n",
    "        dumy = torch.ones(np.prod(np.array(x.data.size()[1]))).cuda()*999999999999999999 # momentnum=1\n",
    "        x = F.batch_norm(x, dumy, dumy, params['bn2.weight'], params['bn2.bias'], True, momentum=1)\n",
    "        x = F.max_pool2d(F.relu(x), 2)\n",
    "        \n",
    "        x = F.conv2d(x, params['conv3.weight'].to(device), params['conv3.bias'].to(device))\n",
    "        dumy = torch.ones(np.prod(np.array(x.data.size()[1]))).cuda()*999999999999999999 # momentnum=1\n",
    "        x = F.batch_norm(x, dumy, dumy, params['bn3.weight'], params['bn3.bias'], True, momentum=1)\n",
    "        x = F.max_pool2d(F.relu(x), 2)\n",
    "        \n",
    "        x = x.view(x.size(0), self.h)\n",
    "        x = F.linear(x, params['fc.weight'].to(device), params['fc.bias'].to(device))\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "def train(model, device, train_data_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    \n",
    "    for data, target in train_data_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        pred = output.max(1, keepdim=True)[1]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        train_acc += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    train_loss /= len(train_data_loader.dataset)\n",
    "    train_acc /= len(train_data_loader.dataset)\n",
    "    return train_loss, train_acc\n",
    "\n",
    "def test(model, device, test_data_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_data_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            \n",
    "            test_loss += loss\n",
    "            test_acc += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_data_loader.dataset)\n",
    "    test_acc /= len(test_data_loader.dataset)\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AugmentedDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OmniglotAugmentedDataset(Dataset):\n",
    "    def __init__(self, path_to_chars, train, train_indices, transform):\n",
    "\n",
    "        self.data = []\n",
    "        self.path = NotImplementedError\n",
    "        \n",
    "        for label_i, (path_to_label, train_index) in enumerate(zip(path_to_chars, train_indices)):\n",
    "            chars = np.array(sorted(os.listdir(path_to_label)))\n",
    "            if train:\n",
    "                chars = chars[train_index]\n",
    "            else:\n",
    "                test_index = list(set(np.arange(20)) - set(train_index)) # omniglot has 20 images per character\n",
    "                chars = chars[test_index]\n",
    "            for char in chars:\n",
    "                path_to_char = os.path.join(path_to_label, char)\n",
    "                image = io.imread(path_to_char)\n",
    "                label_i = np.array(label_i)\n",
    "                self.data.append([image, label_i])\n",
    "            \n",
    "        self.transform = transform\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "        return self.transform(self.data[idx])\n",
    "\n",
    "class ToTensor(object):\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample[0], sample[1]\n",
    "        image = image / 255\n",
    "        image = (image-0.92208)/0.25140\n",
    "        image = image.reshape([28,28, 1])\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        image = np.array(image, np.float32)\n",
    "\n",
    "        return [torch.from_numpy(image), torch.from_numpy(label)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AugmentDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_task_train_data\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true: tensor([5, 8, 2, 4, 9, 1, 7, 3, 0, 6])\n",
      "\n",
      "local_task_test_data\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true: tensor([0, 5, 6, 3, 3, 3, 6, 5, 1, 9])\n"
     ]
    }
   ],
   "source": [
    "train_indices = np.random.randint(20, size=(n_class, n_shot))\n",
    "\n",
    "path_to_chars = [\n",
    "    '../data/omniglot_mini/images_background/Early_Aramaic/character08',\n",
    "    '../data/omniglot_mini/images_background/N_Ko/character05',\n",
    "    '../data/omniglot_mini/images_background/Early_Aramaic/character01',\n",
    "    '../data/omniglot_mini/images_background/Balinese/character04',\n",
    "    '../data/omniglot_mini/images_background/Burmese_(Myanmar)/character21',\n",
    "    '../data/omniglot_mini/images_background/Balinese/character03',\n",
    "    '../data/omniglot_mini/images_background/Gujarati/character35',\n",
    "    '../data/omniglot_mini/images_background/Bengali/character10',\n",
    "    '../data/omniglot_mini/images_background/Burmese_(Myanmar)/character18',\n",
    "    '../data/omniglot_mini/images_background/Armenian/character17'\n",
    "]\n",
    "\n",
    "print(\"local_task_train_data\")\n",
    "local_task_train_data_loader = DataLoader(\n",
    "    OmniglotAugmentedDataset(path_to_chars,\n",
    "                    train=True,\n",
    "                    train_indices=train_indices,\n",
    "                    transform=transforms.Compose([\n",
    "                        ToTensor(),\n",
    "                    ])),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for data, target in local_task_train_data_loader: # only have one batch\n",
    "    plt.figure(figsize=(10,1))\n",
    "    for i, x in enumerate(data):\n",
    "        plt.subplot(1, batch_size, i+1); plt.imshow(x[0])\n",
    "    plt.show()\n",
    "    print(\"y_true:\", target)\n",
    "\n",
    "print(\"\\nlocal_task_test_data\")\n",
    "local_task_test_data_loader = DataLoader(\n",
    "    OmniglotAugmentedDataset(path_to_chars,\n",
    "                    train=False,\n",
    "                    train_indices=train_indices,\n",
    "                    transform=transforms.Compose([\n",
    "                        ToTensor(),\n",
    "                    ])),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for data, target in local_task_test_data_loader: # only have one batch\n",
    "    plt.figure(figsize=(10,1))\n",
    "    for i, x in enumerate(data):\n",
    "        plt.subplot(1, batch_size, i+1); plt.imshow(x[0])\n",
    "    plt.show()\n",
    "    print(\"y_true:\", target)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taskset and TaskLoader classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Taskset(object):\n",
    "    def __getitem__(self, index):\n",
    "        raise NotImplementedError\n",
    "    def __len__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class TaskLoader(object):\n",
    "    def __init__(self, taskset, shuffle=True):\n",
    "        self.taskset = taskset\n",
    "        self.sample_iter = iter(np.random.permutation(np.arange(len(taskset))))\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        return self.taskset[next(self.sample_iter)]\n",
    "    def __len__(self):\n",
    "        return len(self.taskset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AugmentedTaskset (for meta-train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OmniglotAugmentedTaskset(Taskset):\n",
    "    def __init__(self, path_to_omniglot, n_class, n_shot, meta_train):\n",
    "        \n",
    "        if meta_train:\n",
    "            path_to_langs = os.path.join(path_to_omniglot, \"images_background/\")\n",
    "        else:\n",
    "            path_to_langs = os.path.join(path_to_omniglot, \"images_evaluation/\")\n",
    "            \n",
    "        chars = []\n",
    "        \n",
    "        for path_to_lang in os.listdir(path_to_langs):\n",
    "            path_to_chars = os.path.join(path_to_langs, path_to_lang)\n",
    "            for path_to_char in os.listdir(path_to_chars):\n",
    "                chars.append(os.path.join(path_to_chars, path_to_char)) \n",
    "        \n",
    "        random.shuffle(chars)\n",
    "        tasks = list(chunked(chars, n_class))[:-1] # drop_last\n",
    "        \n",
    "        self.tasks = tasks\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tasks)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        train_indices = np.random.randint(20, size=(n_class, n_shot))\n",
    "        return {\"train\":\n",
    "                DataLoader(\n",
    "                    OmniglotAugmentedDataset(self.tasks[idx],\n",
    "                                    train=True,\n",
    "                                    train_indices=train_indices,\n",
    "                                    transform=transforms.Compose([\n",
    "                                        ToTensor()\n",
    "                                    ])),\n",
    "                    batch_size=batch_size, shuffle=True), \n",
    "                \"test\":\n",
    "                DataLoader(\n",
    "                    OmniglotAugmentedDataset(self.tasks[idx],\n",
    "                                    train=False,\n",
    "                                    train_indices=train_indices,\n",
    "                                    transform=transforms.Compose([\n",
    "                                        ToTensor()\n",
    "                                    ])),\n",
    "                    batch_size=batch_size, shuffle=True),\n",
    "                \"task\": self.tasks[idx] \n",
    "               }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AugmentTaskLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n",
      "['../data/omniglot_mini/images_background/Japanese_(katakana)/character41', '../data/omniglot_mini/images_background/Futurama/character11', '../data/omniglot_mini/images_background/Arcadian/character24', '../data/omniglot_mini/images_background/Sanskrit/character41', '../data/omniglot_mini/images_background/Syriac_(Estrangelo)/character14', '../data/omniglot_mini/images_background/Korean/character13', '../data/omniglot_mini/images_background/Mkhedruli_(Georgian)/character39', '../data/omniglot_mini/images_background/Futurama/character12', '../data/omniglot_mini/images_background/Armenian/character05', '../data/omniglot_mini/images_background/Grantha/character15']\n",
      "train\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 2, 4, 7, 6, 8, 1, 0, 5, 9])\n",
      "test\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9, 3, 8, 8, 4, 7, 4, 0, 6, 8])\n"
     ]
    }
   ],
   "source": [
    "meta_train_task_loader = TaskLoader(\n",
    "    OmniglotAugmentedTaskset(\"../data/omniglot_mini/\", meta_train=True, n_class=n_class, n_shot=n_shot)\n",
    ")\n",
    "\n",
    "print(len(meta_train_task_loader.taskset))\n",
    "\n",
    "for i, meta_train_task in enumerate(meta_train_task_loader):\n",
    "    print(meta_train_task[\"task\"])\n",
    "    print(\"train\")\n",
    "    local_task_train_data_loader = meta_train_task[\"train\"]\n",
    "    for data, target in local_task_train_data_loader:\n",
    "        plt.figure(figsize=(10,1))\n",
    "        for j, x in enumerate(data):\n",
    "            plt.subplot(1, batch_size, j+1); plt.imshow(x[0])\n",
    "        plt.show()\n",
    "        print(target)\n",
    "    print(\"test\")\n",
    "    local_task_test_data_loader = meta_train_task[\"test\"]\n",
    "    for data, target in local_task_test_data_loader:\n",
    "        plt.figure(figsize=(10,1))\n",
    "        for j, x in enumerate(data):\n",
    "            plt.subplot(1, batch_size, j+1); plt.imshow(x[0])\n",
    "        plt.show()\n",
    "        print(target)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maml = MAML(model_class=OmniglotNet, model_args={\"n_class\":10}, optim_class=optim.Adam, optim_args={\"lr\":0.001}, loss=F.nll_loss, metrics=None)\n",
    "# maml.meta_train(task_loader)\n",
    "# maml.meta_test(task_loader)\n",
    "\n",
    "# master_net = OmniglotNet(10).to(\"cuda\")\n",
    "# master_opt = optim.Adam(master_net.parameters(), lr=0.001)\n",
    "\n",
    "# model_class=OmniglotNet\n",
    "# model_args={\"n_class\":10}\n",
    "# optim_class=optim.Adam\n",
    "# optim_args={\"lr\":0.001}\n",
    "# model = model_class(**model_args)\n",
    "# print(model)\n",
    "# opt = optim.Adam(model.parameters(), **optim_args)\n",
    "# print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAML(object):\n",
    "    def __init__(self, \n",
    "                 model_class, model_args, \n",
    "                 optim_class, optim_args, \n",
    "                 loss_fn, metrics=None, \n",
    "                 local_epochs=5):\n",
    "        \n",
    "        self.lr = 0.1\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#         self.model_class = model_class\n",
    "#         self.model_args = model_args\n",
    "#         self.optim_class = optim_class\n",
    "#         self.optim_args = optim_args\n",
    "#         self.loss_fn = loss_fn\n",
    "        self.local_epochs = local_epochs # n_local_update\n",
    "        \n",
    "#         self.master_net = self.model_class(**self.model_args).to(self.device)\n",
    "#         self.master_opt = self.optim_class(self.master_net.parameters(), **self.optim_args)\n",
    "#         self.keys = self.master_net.state_dict().keys()\n",
    "    \n",
    "    def copy_params(self, from_net, to_net):\n",
    "        params = {k: v for k, v in from_net.state_dict().items() if k in self.keys}\n",
    "        to_net.load_state_dict(params, strict=False)\n",
    "    \n",
    "    def save(self, model_path):\n",
    "        torch.save(self.master_net.state_dict(), model_path)\n",
    "    \n",
    "    def load(self, model_path):\n",
    "        self.master_net.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    def meta_test(self, tasl_loader):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def meta_train(self, task_loader):\n",
    "        \n",
    "        meta_grads = []\n",
    "        test_loss, test_acc = [], [] # For logging.\n",
    "        \n",
    "        sleep(0.5)\n",
    "        with tqdm(task_loader, desc=\"Meta Train\", ncols=10) as _tqdm:\n",
    "            for task in _tqdm:\n",
    "                \n",
    "                # copy master model to new branch model\n",
    "#                 faster_net = self.model_class(**self.model_args).to(self.device)\n",
    "#                 faster_net.forward = NotImplementedError # goodbye!\n",
    "#                 self.copy_params(self.master_net, faster_net)\n",
    "\n",
    "#                 faster_params = OrderedDict((name, param) for (name, param) in faster_net.named_parameters())\n",
    "\n",
    "                # make local task data loader\n",
    "                train_data_loader = task[\"train\"]\n",
    "                test_data_loader = task[\"test\"]\n",
    "\n",
    "                # ----------------------------------------------------------------\n",
    "                # meta train task train\n",
    "                # ----------------------------------------------------------------\n",
    "\n",
    "                first_train_for_this_task = True\n",
    "\n",
    "                for epoch in range(self.local_epochs):\n",
    "                    \n",
    "                    _train_loss = 0 # For tqdm.\n",
    "                    _train_acc = 0 # For tqdm.\n",
    "                    \n",
    "                    for data, target in train_data_loader:\n",
    "                        data, target = data.to(self.device), target.to(self.device)\n",
    "\n",
    "                        if first_train_for_this_task:\n",
    "#                             # manual predict\n",
    "#                             output = self.master_net(data)\n",
    "#                             loss = self.loss_fn(output, target)\n",
    "#                             pred = output.max(1, keepdim=True)[1]\n",
    "                            \n",
    "#                             _train_loss += loss\n",
    "#                             _train_acc += pred.eq(target.view_as(pred)).sum().item()\n",
    "                            \n",
    "#                             grads = torch.autograd.grad(loss, self.master_net.parameters(), create_graph=True)\n",
    "\n",
    "#                             first_train_for_this_task = False\n",
    "                            pass\n",
    "\n",
    "                        else:\n",
    "#                             # manual predict\n",
    "#                             output = faster_net.manual_forward(data, faster_params)\n",
    "#                             loss = self.loss_fn(output, target)\n",
    "#                             pred = output.max(1, keepdim=True)[1]\n",
    "                            \n",
    "#                             _train_loss += loss\n",
    "#                             _train_acc += pred.eq(target.view_as(pred)).sum().item()\n",
    "                            \n",
    "#                             grads = torch.autograd.grad(loss, faster_params.values(), create_graph=True)\n",
    "                            pass\n",
    "                        # manual optimize!!!\n",
    "#                         faster_params = OrderedDict(\n",
    "#                             (name, param - self.lr*grad)\n",
    "#                             for ((name, param), grad) in zip(faster_params.items(), grads)\n",
    "#                         )\n",
    "                    \n",
    "#                     _train_loss /= len(train_data_loader.dataset)\n",
    "#                     _train_acc /= len(train_data_loader.dataset)\n",
    "                    \n",
    "#                     _tqdm.set_postfix(OrderedDict(\n",
    "#                         epoch=epoch+1, \n",
    "#                         train_loss=\"{:.3f}\".format(_train_loss),\n",
    "#                         train_acc=\"{:.3f}\".format(_train_acc)))\n",
    "                \n",
    "                # ----------------------------------------------------------------\n",
    "                # meta train task test\n",
    "                # ----------------------------------------------------------------\n",
    "                \n",
    "#                 _test_loss = 0 # For logging.\n",
    "#                 # _test_acc = 0 # For logging.\n",
    "                \n",
    "#                 for data, target in test_data_loader:\n",
    "#                     data, target = data.to(self.device), target.to(self.device)\n",
    "\n",
    "#                     output = faster_net.manual_forward(data, faster_params)\n",
    "#                     loss = self.loss_fn(output, target) # test_loss計算するとこまではfaster_net\n",
    "\n",
    "#                     # differentiates test_loss by master_net params\n",
    "#                     grads = torch.autograd.grad(loss, self.master_net.parameters(), retain_graph=True)\n",
    "#                     grads = {name:g for ((name, _), g) in zip(faster_net.named_parameters(), grads)}\n",
    "#                     meta_grads.append(grads)\n",
    "\n",
    "#                     # pred = output.max(1, keepdim=True)[1]\n",
    "#                     # acc = pred.eq(target.view_as(pred)).sum()\n",
    "                    \n",
    "#                     _test_loss += loss.item()\n",
    "#                     # _test_acc += acc.item()\n",
    "                \n",
    "#                 _test_loss /= len(test_data_loader.dataset)\n",
    "#                 # _test_acc /= len(test_data_loader.dataset)  \n",
    "#                 test_loss.append(_test_loss)\n",
    "                # test_acc.append(_test_acc)\n",
    "                print(\"break\")\n",
    "                break\n",
    "        \n",
    "        # ----------------------------------------------------------------\n",
    "        # end all tasks\n",
    "        # ----------------------------------------------------------------\n",
    "        \n",
    "        # ----------------------------------------------------------------\n",
    "        # meta update\n",
    "        # ----------------------------------------------------------------\n",
    "#         print(meta_grads)\n",
    "#         meta_grads = {k: sum(grads[k] for grads in meta_grads) for k in meta_grads[0].keys()}\n",
    "        \n",
    "#         # using data,target from somewhere\n",
    "#         dumy_output = self.master_net(data)\n",
    "#         dumy_loss = self.loss_fn(dumy_output, target)\n",
    "        \n",
    "#         # after dumy_loss.backward, rewrite grads\n",
    "#         self.master_opt.zero_grad()\n",
    "#         dumy_loss.backward(retain_graph=True)\n",
    "\n",
    "#         hooks = []\n",
    "#         for (k,v) in self.master_net.named_parameters():\n",
    "#             def get_closure():\n",
    "#                 key = k\n",
    "#                 def replace_grad(grad):\n",
    "#                     return meta_grads[key]\n",
    "#                 return replace_grad\n",
    "#             hooks.append(v.register_hook(get_closure()))\n",
    "\n",
    "#         # Compute grads for current step, replace with summed gradients as defined by hook\n",
    "#         self.master_opt.zero_grad()\n",
    "#         dumy_loss.backward()\n",
    "\n",
    "#         # Update the net parameters with the accumulated gradient according to optimizer\n",
    "#         self.master_opt.step()\n",
    "\n",
    "#         # Remove the hooks before next training phase\n",
    "#         for h in hooks:\n",
    "#             h.remove()\n",
    "\n",
    "        return 0, 0#np.mean(test_loss), np.mean(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta Train:   0%| | 0/96 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "break\n",
      "# 1 (meta-train-task) test_loss: 0.000000, test_acc: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta Train:   0%| | 0/96 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "break\n",
      "# 2 (meta-train-task) test_loss: 0.000000, test_acc: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta Train:   0%| | 0/96 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "break\n",
      "# 3 (meta-train-task) test_loss: 0.000000, test_acc: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta Train:   0%| | 0/96 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "break\n",
      "# 4 (meta-train-task) test_loss: 0.000000, test_acc: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta Train:   0%| | 0/96 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "break\n",
      "# 5 (meta-train-task) test_loss: 0.000000, test_acc: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Meta Train:   0%| | 0/96 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "break\n",
      "# 6 (meta-train-task) test_loss: 0.000000, test_acc: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-21663b9be90a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     task_loader = TaskLoader(\n\u001b[1;32m     16\u001b[0m         OmniglotAugmentedTaskset(\"../data/omniglot_mini/\", meta_train=True, n_class=n_class, n_shot=n_shot))\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;31m#     test_loss, test_acc = meta_learner.meta_test()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-8ee321862f93>\u001b[0m in \u001b[0;36mmeta_train\u001b[0;34m(self, task_loader)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# For logging.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Meta Train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_tqdm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_tqdm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "meta_learner = MAML(model_class=OmniglotNet, model_args={\"n_class\":10}, \n",
    "                    optim_class=optim.Adam, optim_args={\"lr\":0.001}, \n",
    "                    loss_fn=F.nll_loss, metrics=None)\n",
    "\n",
    "\n",
    "\n",
    "# see normal few-shot learning\n",
    "# for _ in range(1):\n",
    "#     test_loss, test_acc = meta_learner.meta_test()\n",
    "#     print(\"# {}  (meta-test-task) test_loss: {:.6f}, test_acc: {:.6f}\".format(\n",
    "#         0, test_loss, test_acc))\n",
    "\n",
    "for epoch in range(10):\n",
    "    # TODO: shuffle\n",
    "    task_loader = TaskLoader(\n",
    "        OmniglotAugmentedTaskset(\"../data/omniglot_mini/\", meta_train=True, n_class=n_class, n_shot=n_shot))\n",
    "    train_loss, train_acc = meta_learner.meta_train(task_loader)\n",
    "#     test_loss, test_acc = meta_learner.meta_test()\n",
    "    \n",
    "    print(\"# {} (meta-train-task) test_loss: {:.6f}, test_acc: {:.6f}\".format(\n",
    "        epoch+1, train_loss, train_acc))    \n",
    "#     print(\"# {}  (meta-test-task) test_loss: {:.6f}, test_acc: {:.6f}\".format(\n",
    "#         epoch+1, test_loss, test_acc))\n",
    "    \n",
    "#     model_path = \"../model/model-epoch_{:05}-train_loss_{:0.3f}-train_acc_{:0.3f}-test_loss_{:0.3f}-test_acc_{:0.3f}.pt\".format(\n",
    "#         epoch, train_loss, train_acc, test_loss, test_acc)\n",
    "    \n",
    "#     meta_learner.save(model_path)\n",
    "#     meta_learner.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MetaLearner' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-59bdc9bc9782>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmeta_learner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMetaLearner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# see normal few-shot learning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MetaLearner' is not defined"
     ]
    }
   ],
   "source": [
    "meta_learner = MetaLearner()\n",
    "\n",
    "# see normal few-shot learning\n",
    "for _ in range(1):\n",
    "    test_loss, test_acc = meta_learner.meta_test()\n",
    "    print(\"# {}  (meta-test-task) test_loss: {:.6f}, test_acc: {:.6f}\".format(\n",
    "        0, test_loss, test_acc))\n",
    "\n",
    "for epoch in range(1000):\n",
    "    \n",
    "    train_loss, train_acc = meta_learner.meta_train()\n",
    "    test_loss, test_acc = meta_learner.meta_test()\n",
    "    \n",
    "    print(\"# {} (meta-train-task) test_loss: {:.6f}, test_acc: {:.6f}\".format(\n",
    "        epoch+1, train_loss, train_acc))    \n",
    "    print(\"# {}  (meta-test-task) test_loss: {:.6f}, test_acc: {:.6f}\".format(\n",
    "        epoch+1, test_loss, test_acc))\n",
    "    \n",
    "    model_path = \"../model/model-epoch_{:05}-train_loss_{:0.3f}-train_acc_{:0.3f}-test_loss_{:0.3f}-test_acc_{:0.3f}.pt\".format(\n",
    "        epoch, train_loss, train_acc, test_loss, test_acc)\n",
    "    \n",
    "    meta_learner.save(model_path)\n",
    "#     meta_learner.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
